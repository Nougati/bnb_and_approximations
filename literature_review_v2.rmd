---
 title: 'Literature Review: Implicit enumeration with dual bounds from approximations'
 author: Nelson Frew
 output: pdf_document
---


** Discrete Optimisation solves "these" problems **

The field of Discrete Optimisation studies methods to solve optimisation problems where variables may be constrained to take discrete values (for example, integers) to be valid for a solution. Classic problems in Discrete Optimisation include scheduling, shortest path problems, and the Knapsack problem. 

** We can solve such problems with MIP techniques **

Mixed-Integer Programming (MIP) refers to a set of modelling and solving techniques where at least one of the variable must be integer. 

** The state of the art for MIP is B&B **

We can often formulate Discrete Optimisation problems as Mixed-Integer Programs; the state of the art method for solving problems in MIP to use the Branch-and-Bound (B&B) approach, introduced by Land and Doig (1960) with further work done by Dakin (1965).

** B&B works like this; key to its performance is branching, pruning and searching **

The essence of the B&B approach resides in partially enumerating through possible solutions in order to derive bounds on where the optimal value can be. 
By establishing bounds on what can possibly be a solution, we can prune our enumeration tree down each branch which cannot possibly permit values in this range, a process referred to as *bounding*.
 If a partially enumerated solution doesn't violate our bounds, we create "children" solutions that partially enumerate from the parent solution further, known as *branching*.
 If partial enumeration yields a feasible solution, with a value better than our current bound, we update our bound to better inform the bounding of future solutions.
 As a result, when we have enumerated through the solutions which our bounds have permitted, we will have found the optimal solution. The bounds which facilitate the bounding process are known as the *primal* and *dual bounds* of the search, which, for a maximisation problem, would correspond to the*upper* and *lower* bounds on the optimal value, respectively.  
As such, the main ways to improve the performance of a B&B resides in improves its *branching*, *bounding*, and *searching* strategies.

** Branching is hard! ** 

** 'Finding' dual bounds **

** SDP, SDP relaxations, Lagrange and lagrange relaxations, LP and LP relaxations **

** B&B with regards to cutting planes, presolvers and primal heuristics **

** Description of Warm starting **

** Using hard problems as a common denominator, Approximations research and their interest proving high quality $\alpha$-approx algos, into quality guarantees **

** Knapsack case study: Dynamic Programming, FPTAS's, pseudopolynomial time solutions **

** Exploiting Problem structure vs the one-size-fits-all LP: "Some things are easier to obtain via combinatorial algorithms than LP (blossom algorithm vs blossom inequalities" **

** Quality guarantees and hwo this relates back to LP's folly in the face of problems **

** Wolsey and his magical mystery tour **

** Extending from here with construction of duals w/ AAs **

** Conclude: we have all these assets, here is where this positions us**


